{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSP(Sleep Sensor Prediction)_JY [2]-[3]\n",
    "* Time-series Classification\n",
    "* GRU-ATT-GRU\n",
    "* 특성 추가\n",
    "* 5.9636025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas numpy matplotlib seaborn scikit-learn torch xgboost lightgbm catboost pyarrow fastparquet py7zr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: saved\\epoch=550-step=3857-v1.ckpt\n",
      "Deleted: saved\\epoch=550-step=3857.ckpt\n",
      "Deleted: saved\\epoch=999-step=7000.ckpt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "directory_path = 'saved'\n",
    "\n",
    "for root, dirs, files in os.walk(directory_path):\n",
    "    for file in files:\n",
    "        if file.endswith(\".ckpt\"):\n",
    "            file_path = os.path.join(root, file)\n",
    "            os.remove(file_path)\n",
    "            print(f\"Deleted: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'SSP_JY_cuda'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "plt.rc('font', family='Malgun Gothic')\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rc('axes', unicode_minus=False)\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchsummary import summary\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "# import wandb\n",
    "# from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "parser = ArgumentParser(description=\"SSP_JY\")\n",
    "\n",
    "## DATA\n",
    "parser.add_argument(\"--valid_path\", default=\"./data\", type=str)\n",
    "parser.add_argument(\"--test_path\", default=\"./data\", type=str)\n",
    "parser.add_argument('--window_size', default=24, type=int)  # 수면 시간 고려하여 설정하였음\n",
    "parser.add_argument('--stride_size', default=1, type=int)  # 1시간 단위로 봄\n",
    "\n",
    "## MHA\n",
    "parser.add_argument('--num_head', default=8, type=int)\n",
    "parser.add_argument('--hid_dim', default=128, type=int)\n",
    "\n",
    "## TRAIN\n",
    "parser.add_argument('--optimizer', default=\"adamw\", type=str)\n",
    "parser.add_argument(\"--learning_rate\", default=1e-4, type=float)\n",
    "parser.add_argument(\"--weight_decay\", default=0, type=float)\n",
    "parser.add_argument('--scheduler', default=\"step\", type=str)\n",
    "parser.add_argument('--batch_size', default=16, type=int)\n",
    "parser.add_argument('--epochs', default=1000, type=int)\n",
    "parser.add_argument('--patience', default=100, type=int)\n",
    "\n",
    "parser.add_argument('--cv', default=5, type=int)\n",
    "parser.add_argument('--seed', default=42, type=int)\n",
    "parser.add_argument('--mixed_precision', default=32, type=int)\n",
    "parser.add_argument('--device', nargs='+', default=[0], type=int)\n",
    "parser.add_argument('--num_workers', default=0, type=int)\n",
    "\n",
    "args = parser.parse_args('')\n",
    "\n",
    "# wandb.init(config=args, name='SSP_JY(GAG)', project=\"ETRI_Baseline\")\n",
    "# wandb_logger = WandbLogger(name='SSP_JY(GAG)', project=\"ETRI_Baseline\")\n",
    "# wandb.config.update(args)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "CFG = {\n",
    "    \"WINDOW_SIZE\" : args.window_size,\n",
    "    \"STRIDE_SIZE\" : args.stride_size,\n",
    "    \"BATCH_SIZE\" : args.batch_size,\n",
    "    \"EPOCHS\"     : args.epochs,\n",
    "    \"PATIENCE\"   : args.patience,\n",
    "    \"CV\"         : args.cv,\n",
    "    \"SEED\"       : args.seed,\n",
    "    \"VALID_PATH\" : args.valid_path,\n",
    "    \"TEST_PATH\"  : args.test_path,\n",
    "}\n",
    "\n",
    "def seed_everything(SEED):\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    L.seed_everything(SEED)\n",
    "\n",
    "torch.set_float32_matmul_precision('high') \n",
    "seed_everything(CFG['SEED'])\n",
    "\n",
    "idx = f\"{parser.description}_{device}\"\n",
    "idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataloader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = pd.read_csv('./data/val_label.csv')\n",
    "test_label  = pd.read_csv('./data/answer_sample.csv')\n",
    "\n",
    "train_label['date'] = pd.to_datetime(train_label['date'])\n",
    "test_label['date']  = pd.to_datetime(test_label['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2520, 19), (2760, 19))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(os.path.join(CFG['VALID_PATH'],'train_data2.csv'))\n",
    "test_data  = pd.read_csv(os.path.join(CFG['TEST_PATH'], 'test_data2.csv'))\n",
    "\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dict = {}\n",
    "\n",
    "for id in [1, 2, 3, 4]:\n",
    "    train_data_dict[f'train_macc_{id}'] = pd.read_csv(os.path.join(CFG['VALID_PATH'], f'train_macc_{id}-2.csv'))\n",
    "\n",
    "test_data_dict = {}\n",
    "\n",
    "for id in [5, 6, 7, 8]:\n",
    "    test_data_dict[f'test_macc_{id}'] = pd.read_csv(os.path.join(CFG['TEST_PATH'], f'test_macc_{id}-2.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2520, 6), (2760, 6))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = train_data_dict.keys()\n",
    "train_macc = pd.DataFrame()\n",
    "\n",
    "for key in keys:\n",
    "    train_macc = pd.concat([train_macc, train_data_dict[key]], axis=0)\n",
    "\n",
    "keys = test_data_dict.keys()\n",
    "test_macc = pd.DataFrame()\n",
    "\n",
    "for key in keys:\n",
    "    test_macc = pd.concat([test_macc, test_data_dict[key]], axis=0)\n",
    "\n",
    "train_macc.fillna(0, inplace=True)\n",
    "test_macc.fillna(0, inplace=True)\n",
    "\n",
    "train_macc.shape, test_macc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.merge(train_macc, on=['subject_id', 'hour'], how='left')\n",
    "test_data  = test_data.merge(test_macc, on=['subject_id', 'hour'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## categorical feature 처리\n",
    "\n",
    "def Info2Idx(df, cat_feat):\n",
    "    info2idx = {}\n",
    "    for f in cat_feat:\n",
    "        f_unique    = df[f].unique()\n",
    "        info2idx[f] = {k:v+1 for v, k in enumerate(f_unique)}\n",
    "    return info2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['hour'] = pd.to_datetime(train_data['hour'])\n",
    "test_data['hour']  = pd.to_datetime(test_data['hour'])\n",
    "\n",
    "train_data['time'] = train_data['hour'].dt.hour.astype(float)\n",
    "test_data['time']  = test_data['hour'].dt.hour.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['month'] = train_data['hour'].dt.month.astype(float)\n",
    "test_data['month']  = test_data['hour'].dt.month.astype(float)\n",
    "\n",
    "train_data['day'] = train_data['hour'].dt.dayofweek.astype(float)\n",
    "test_data['day']  = test_data['hour'].dt.dayofweek.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feat = ['activity', 'month', 'max_ambience_cls']\n",
    "total_cat = pd.concat([train_data.loc[:, cat_feat], test_data.loc[:, cat_feat]], axis=0)\n",
    "\n",
    "info2idx = Info2Idx(total_cat, cat_feat)\n",
    "\n",
    "## categorical 변수가 1개인 경우\n",
    "# train_data[cat_feat[0]] = train_data[cat_feat[0]].map(info2idx[cat_feat[0]])\n",
    "# test_data[cat_feat[0]]  = test_data[cat_feat[0]].map(info2idx[cat_feat[0]])\n",
    "\n",
    "train_data[cat_feat] = train_data[cat_feat].apply(lambda x: x.map(info2idx[x.name]))\n",
    "test_data[cat_feat]  = test_data[cat_feat].apply(lambda x: x.map(info2idx[x.name]))\n",
    "\n",
    "# args.f_sizes = [len(info2idx[i])+1 for i in cat_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject_id', 'hour', 'activity', 'distance', 'max_light_x',\n",
       "       'mean_light_x', 'mean_burned_calories', 'mean_running_steps',\n",
       "       'mean_steps', 'sum_burned_calories', 'sum_running_steps', 'sum_steps',\n",
       "       'max_hr', 'mean_hr', 'max_light_y', 'mean_light_y',\n",
       "       'app_total_use_time', 'app_mean_use_time', 'max_ambience_cls',\n",
       "       'average_x', 'average_y', 'average_z', 'average_magnitude', 'time',\n",
       "       'month', 'day'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(X, Y, window_size=CFG['WINDOW_SIZE'], stride=CFG['STRIDE_SIZE'], for_train=True):\n",
    "    \n",
    "    if for_train:\n",
    "        ids = [1,2,3,4]\n",
    "        df_label = train_label.copy()\n",
    "    else:\n",
    "        ids = [5,6,7,8]\n",
    "        df_label = test_label.copy()\n",
    "    \n",
    "    train_sequences = []\n",
    "    valid_sequences = []\n",
    "\n",
    "    train_sequences_labels = []\n",
    "    valid_sequences_labels = []\n",
    "\n",
    "    train_cols = [\n",
    "        'activity', 'distance', 'mean_light_x', 'mean_burned_calories', 'mean_running_steps', 'mean_steps', \n",
    "        'mean_hr', 'mean_light_y', 'average_x', 'average_y', 'average_z', 'average_magnitude',\n",
    "        'app_total_use_time', 'max_ambience_cls',\n",
    "        # 'time', 'day', 'month'\n",
    "                    ]\n",
    "    \n",
    "    label_cols = ['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3', 'S4']\n",
    "\n",
    "    for id in ids:\n",
    "\n",
    "        dates = df_label.loc[df_label.subject_id == id, 'date'].dt.date\n",
    "        \n",
    "        for idx, date in enumerate(dates):\n",
    "            \n",
    "            user_data  = X.loc[(X.subject_id == id) & (X.hour.dt.date == date), train_cols]\n",
    "            user_label = Y.loc[(Y.subject_id == id) & (Y.date.dt.date == date), label_cols]\n",
    "\n",
    "            user_data  = user_data.values\n",
    "            user_label = user_label.values\n",
    "            end = len(user_data) - window_size + 1\n",
    "            \n",
    "            for i in range(0, end, stride):\n",
    "                if (idx == 0) & for_train :\n",
    "                    valid_sequences.append(user_data[i : i + window_size, :])\n",
    "                    valid_sequences_labels.append(user_label)\n",
    "                elif for_train:\n",
    "                    train_sequences.append(user_data[i : i + window_size, :])\n",
    "                    train_sequences_labels.append(user_label)\n",
    "                else:\n",
    "                    train_sequences.append(user_data[i : i + window_size, :])\n",
    "                    train_sequences_labels.append(user_label)\n",
    "    \n",
    "    if for_train:\n",
    "        return np.array(train_sequences), np.array(train_sequences_labels), np.array(valid_sequences), np.array(valid_sequences_labels)\n",
    "    else:\n",
    "        return np.array(train_sequences), np.array(train_sequences_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((101, 24, 14),\n",
       " (101, 1, 7),\n",
       " (4, 24, 14),\n",
       " (4, 1, 7),\n",
       " (115, 24, 14),\n",
       " (115, 1, 7))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_window_data, train_window_labels, valid_window_data, valid_window_labels = make_dataset(train_data, train_label, window_size=CFG['WINDOW_SIZE'], stride=CFG['STRIDE_SIZE'], for_train=True)\n",
    "test_window_data, test_window_labels  = make_dataset(test_data, test_label, window_size=CFG['WINDOW_SIZE'], stride=CFG['STRIDE_SIZE'], for_train=False)\n",
    "\n",
    "train_window_data.shape, train_window_labels.shape, valid_window_data.shape, valid_window_labels.shape, test_window_data.shape, test_window_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        X = torch.tensor(self.X[index], dtype=torch.float32)\n",
    "        \n",
    "        if self.Y is not None:\n",
    "            Y = torch.tensor(self.Y[index], dtype=torch.float32)\n",
    "            return X, Y\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUWithMultiHeadAttention(nn.Module):\n",
    "    def __init__(self, hidden_size, num_heads):\n",
    "        super(GRUWithMultiHeadAttention, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.gru_in    = nn.GRU(hidden_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.fc        = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.attention = nn.MultiheadAttention(hidden_size, num_heads)\n",
    "        self.gru_out   = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        outputs, hidden = self.gru_in(x)                                # BxTx(Direction * H)\n",
    "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:],hidden[-1,:,:]),dim = 1))).unsqueeze(0)\n",
    "        outputs = self.fc(outputs)                                      # BxTxH\n",
    "\n",
    "        context_vec, _ = self.attention(outputs, outputs, outputs)      # BxTxH\n",
    "        \n",
    "        gru_input = context_vec[:, -1:, :]\n",
    "        gru_output, _ = self.gru_out(gru_input, hidden)                 # BxTxH\n",
    "        \n",
    "        return gru_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, args, input_size=8, hidden_size=args.hid_dim):\n",
    "        super(BaseModel, self).__init__()\n",
    "        \n",
    "        # 1D Convolution layers\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv1d(input_size, hidden_size//2, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm1d(hidden_size//2),\n",
    "            nn.ReLU()\n",
    "            )\n",
    "        \n",
    "        # Bidirectional GRU with Attention\n",
    "        self.gru_attention = GRUWithMultiHeadAttention(hidden_size//2, num_heads=args.num_head)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size//2, 7),\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = x.permute(0, 2, 1)                  # BxTxF -> BxFxT\n",
    "        x = self.conv_block(x)                  # BxHxT'\n",
    "        x = x.permute(0, 2, 1)                  # BxT'xH\n",
    "        \n",
    "        gru_output = self.gru_attention(x)      # BxT'x(Direction * H)\n",
    "        output     = self.fc(gru_output[:, -1, :])  # Bx(Direction * H) -> Bx1\n",
    "\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseClassifier(L.LightningModule):\n",
    "    def __init__(self, backbone, args):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "\n",
    "    def forward(self, x):\n",
    "        predictions = self.backbone(x)\n",
    "        return predictions\n",
    "\n",
    "    def step(self, batch):\n",
    "        x, y = batch\n",
    "        y_hat = self.backbone(x)\n",
    "        loss = nn.BCELoss()(y_hat, y.squeeze())\n",
    "        return loss, y, y_hat\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, y, y_hat = self.step(batch)\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, y, y_hat = self.step(batch)\n",
    "        self.log('val_loss', loss, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, y, y_hat = self.step(batch)\n",
    "        self.log(\"test_mae\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        y_hat = self.forward(x)\n",
    "        return y_hat\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if args.optimizer == \"sgd\":\n",
    "            optimizer = torch.optim.SGD(self.parameters(), lr=args.learning_rate, momentum=0.9)\n",
    "        if args.optimizer == \"adam\":\n",
    "            optimizer = torch.optim.Adam(self.parameters(), lr=args.learning_rate)\n",
    "        if args.optimizer == \"adamw\":\n",
    "            optimizer = torch.optim.AdamW(self.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "        \n",
    "        if args.scheduler == \"none\":\n",
    "            return optimizer\n",
    "        if args.scheduler == \"step\":\n",
    "            scheduler = StepLR(\n",
    "                optimizer=optimizer,\n",
    "                step_size=250,\n",
    "                gamma=0.05,\n",
    "            )\n",
    "            return [optimizer], [scheduler]\n",
    "        if args.scheduler == \"cosine\":\n",
    "            scheduler = CosineAnnealingLR(\n",
    "                optimizer=optimizer,\n",
    "                T_max=args.epochs,\n",
    "                eta_min=1e-6,\n",
    "            )\n",
    "            return [optimizer], [scheduler]\n",
    "        if args.scheduler == \"plateau\":\n",
    "            scheduler = ReduceLROnPlateau(\n",
    "                optimizer=optimizer,\n",
    "                mode=\"min\",\n",
    "                factor=0.1,\n",
    "                patience=2, # 2\n",
    "                verbose=False,\n",
    "            )\n",
    "            return {\"optimizer\":optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_loss\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        val_loss            0.6302194595336914\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "val_loss: 0.6302194595336914\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CustomDataset(train_window_data, train_window_labels)\n",
    "valid_dataset = CustomDataset(valid_window_data, valid_window_labels)\n",
    "test_dataset  = CustomDataset(test_window_data, test_window_labels)\n",
    "\n",
    "train_loader  = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n",
    "valid_loader  = DataLoader(valid_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)\n",
    "test_loader   = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)\n",
    "\n",
    "##\n",
    "model   = BaseClassifier(BaseModel(args, input_size=train_window_data.shape[2]), args)\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"train_loss\", \n",
    "    patience=CFG['PATIENCE'], \n",
    "    mode=\"min\"\n",
    "    )\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=os.path.join(os.getcwd(),'saved'),\n",
    "    save_top_k=1,\n",
    "    verbose=False,\n",
    "    monitor='train_loss',\n",
    "    mode='min',\n",
    "    )\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=CFG[\"EPOCHS\"], accelerator=\"auto\", \n",
    "    enable_progress_bar=False,\n",
    "    enable_model_summary=False,\n",
    "    callbacks=[early_stop_callback, checkpoint_callback],\n",
    "    devices=args.device#, logger=wandb_logger,\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_loader, valid_loader)\n",
    "checkpoint_callback.best_model_path\n",
    "\n",
    "eval_dict = trainer.validate(model, dataloaders=valid_loader)[0]\n",
    "valid_loss = eval_dict[\"val_loss\"]\n",
    "\n",
    "y_valid_preds = trainer.predict(model, dataloaders=valid_loader)\n",
    "y_preds = trainer.predict(model, dataloaders=test_loader)\n",
    "\n",
    "print(f\"val_loss: {valid_loss}\")\n",
    "# wandb.log({'val_loss': valid_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 7)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_valid_pred = torch.vstack(y_valid_preds)\n",
    "final_valid_pred = final_valid_pred.cpu().numpy()\n",
    "final_valid_pred = np.where(final_valid_pred > 0.5, 1, 0)\n",
    "final_valid_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score_1: 1.2000000000000002\n",
      "f1_score_2: 1.2857142857142856\n",
      "f1_score_3: 0.8\n",
      "f1_score_4: 0.0\n",
      "f1_score_5: 1.0\n",
      "f1_score_6: 0.75\n",
      "f1_score_7: 1.0\n",
      "total_f1: 6.035714285714286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "total_f1 = 0\n",
    "fina_valid_real = valid_window_labels.squeeze(1)\n",
    "\n",
    "for i in range(7):\n",
    "\n",
    "    if i == 2:\n",
    "        weight = 1.0\n",
    "    else:\n",
    "        weight = 1.5\n",
    "    \n",
    "    f1 = f1_score(fina_valid_real[:,i], final_valid_pred[:,i])\n",
    "    f1 *= weight\n",
    "    total_f1 += f1\n",
    "\n",
    "    print(f\"f1_score_{i+1}: {f1}\")\n",
    "    # wandb.log({f'f1_score_{i+1}': f1})\n",
    "print(f\"total_f1: {total_f1}\")\n",
    "# wandb.log({'total_f1': total_f1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115, 7)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_preds = torch.vstack(y_preds)\n",
    "final_preds = final_preds.cpu().numpy()\n",
    "final_preds = np.where(final_preds > 0.5, 1, 0)\n",
    "final_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = ['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3', 'S4']\n",
    "for_barplot = pd.DataFrame(final_preds, columns=x)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(train_label.iloc[:, 2:].sum(0)/ 105, alpha=0.3, label='train', color='blue')\n",
    "sns.barplot(for_barplot.sum(0)/115, alpha=0.3, label='pred', color='red')\n",
    "\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Q1  Q2  Q3  S1  S2  S3  S4\n",
      "subject_id                            \n",
      "5            4  19   0   0   0   1   0\n",
      "6           22  29   9   0   6  25   1\n",
      "7           33  33  18   0  29  31  29\n",
      "8           25  27   1   9   3   9   8\n"
     ]
    }
   ],
   "source": [
    "for_barplot['subject_id'] = test_label.subject_id.values\n",
    "print(for_barplot.groupby('subject_id').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Q1            0.730435\n",
       " Q2            0.939130\n",
       " Q3            0.243478\n",
       " S1            0.078261\n",
       " S2            0.330435\n",
       " S3            0.573913\n",
       " S4            0.330435\n",
       " subject_id    6.617391\n",
       " dtype: float64,\n",
       " Q1             84\n",
       " Q2            108\n",
       " Q3             28\n",
       " S1              9\n",
       " S2             38\n",
       " S3             66\n",
       " S4             38\n",
       " subject_id    761\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_barplot.iloc[:, :].sum(0)/ 115, for_barplot.iloc[:, :].sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "date = str(now.date()).replace('-', '_')\n",
    "time = str(now.time()).replace(':', '_')\n",
    "\n",
    "submmit = pd.read_csv('./data/answer_sample.csv')\n",
    "submmit.iloc[:, 2:] = final_preds\n",
    "submmit.to_csv(f'./submission/submission_{idx}_{date}_{time}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>date</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2023-11-05</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2023-11-06</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2023-11-07</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2023-11-08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2023-11-09</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>8</td>\n",
       "      <td>2023-11-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>8</td>\n",
       "      <td>2023-11-06</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>8</td>\n",
       "      <td>2023-11-07</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>8</td>\n",
       "      <td>2023-11-08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>8</td>\n",
       "      <td>2023-11-09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subject_id        date  Q1  Q2  Q3  S1  S2  S3  S4\n",
       "0             5  2023-11-05   0   1   0   1   0   0   0\n",
       "1             5  2023-11-06   0   1   0   0   0   0   0\n",
       "2             5  2023-11-07   1   1   0   0   0   0   0\n",
       "3             5  2023-11-08   0   1   1   1   0   0   0\n",
       "4             5  2023-11-09   0   1   0   1   0   0   0\n",
       "..          ...         ...  ..  ..  ..  ..  ..  ..  ..\n",
       "110           8  2023-11-05   1   0   0   1   1   0   1\n",
       "111           8  2023-11-06   1   0   0   1   0   0   0\n",
       "112           8  2023-11-07   1   1   0   1   0   0   0\n",
       "113           8  2023-11-08   0   1   0   0   0   0   0\n",
       "114           8  2023-11-09   1   1   0   0   1   0   0\n",
       "\n",
       "[115 rows x 9 columns]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submmit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
